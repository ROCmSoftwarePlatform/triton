{"hash": "ab7b3fb6ab5547fb33a343c489cf193ac374f8b7477c5014336714dc608ae322", "target": {"backend": "hip", "arch": "gfx942", "warp_size": 64}, "num_warps": 8, "waves_per_eu": 0, "num_stages": 2, "num_ctas": 1, "extern_libs": [["ocml", "/home/dtanner/repos/triton/python/triton/backends/amd/lib/ocml.bc"], ["ockl", "/home/dtanner/repos/triton/python/triton/backends/amd/lib/ockl.bc"]], "cluster_dims": [1, 1, 1], "debug": false, "sanitize_overflow": true, "arch": "gfx942", "supported_fp8_dtypes": ["fp8e4b8", "fp8e4nv", "fp8e5", "fp8e5b16"], "deprecated_fp8_dtypes": [], "default_dot_input_precision": "ieee", "allowed_dot_input_precisions": ["ieee"], "enable_fp_fusion": true, "matrix_instr_nonkdim": 16, "kpack": 2, "allow_flush_denorm": false, "max_num_imprecise_acc_default": 0, "backend_name": "hip", "instruction_sched_variant": "none", "warp_size": 64, "TRITON_MFMA_TILE_ENABLE_SCHED_BARRIERS": "true", "shared": 65536, "name": "matmul_kernel"}